# -*- coding: utf-8 -*-
"""Cria√ß√£o do dataset

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MUQ1lp1N-9AE0W8YrFqZ1vjlnTMIi11H
"""

# =========================
# Apenas 1 Prompt
# =========================

NOME_ARQUIVO_EXCEL = "LICITA_plus_dataset_template.xlsx"
PASTA_DRIVE = "My Drive/üìÅ FACULDADE/2025 - 8¬∫ Per√≠odo/Trabalho de Conclus√£o de Curso II"

OPENAI_API_KEY = ""      # use Secrets (google.colab.userdata)
ANTHROPIC_API_KEY = ""   # use Secrets
DEEPSEEK_API_KEY = ""    # use Secrets

# Execu√ß√µes para m√©dia
N_EXECUCOES_PRECO = 10
SLEEP_ENTRE_CHAMADAS = 1.0  # seg

# Logging / Auditoria
VERBOSO = True
LOG_RAW_RESPOSTA = False     # True = inclui a resposta bruta no TXT
LOG_SALVAR_TXT = True        # True = salva o arquivo de logs no final
LOG_REGISTROS = []           # buffer de logs

# =========================
# Instala√ß√£o de deps
# =========================

import subprocess, sys
def instalar():
    deps = [
        "openai>=1.3.0",
        "anthropic>=0.18.0",
        "pandas>=1.5.0",
        "openpyxl>=3.1.0",
        "numpy>=1.23.0",
        "tqdm>=4.66.0"
    ]
    for dep in deps:
        subprocess.check_call([sys.executable, "-m", "pip", "install", dep, "-q"])
instalar()

# =========================
# Imports
# =========================

import pandas as pd
import numpy as np
import openai
import anthropic
import time
import os
import re
from datetime import datetime
from tqdm.auto import tqdm

# =========================
# APIs
# =========================

from google.colab import userdata

OPENAI_API_KEY = userdata.get('OPENAI_API_KEY') or OPENAI_API_KEY
ANTHROPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY') or ANTHROPIC_API_KEY
DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY') or DEEPSEEK_API_KEY

openai.api_key = OPENAI_API_KEY
cliente_anthropic = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)
cliente_deepseek = openai.OpenAI(api_key=DEEPSEEK_API_KEY, base_url="https://api.deepseek.com")

print("[OK] APIs configuradas", flush=True)

# =========================
# Google Drive
# =========================

from google.colab import drive
drive.mount('/content/drive', force_remount=True)
print("[OK] Drive montado", flush=True)

# =========================
# Utilit√°rios
# =========================

NUM_REGEX = re.compile(r'(\d{1,6}(?:[.,]\d{1,2})?)')

def extrair_preco(texto):
    if not texto:
        return None
    m = NUM_REGEX.findall(str(texto))
    if not m:
        return None
    try:
        v = float(m[0].replace(',', '.'))
        if 1 <= v <= 50000:
            return round(v, 2)
    except:
        return None
    return None

def logf(msg):
    # grava no buffer e deixa a sa√≠da enxuta no colab
    LOG_REGISTROS.append(msg)

def salvar_logs_txt(pasta_drive):
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    caminho = f"/content/drive/{pasta_drive}/logs_execucao_{ts}.txt"
    with open(caminho, "w", encoding="utf-8") as f:
        f.write("\n".join(LOG_REGISTROS))
        f.write("\n")
    print(f"[OK] Log salvo: {os.path.basename(caminho)}", flush=True)
    return caminho

# =========================
# Planilha
# =========================

def carregar_planilha(nome_arquivo, pasta_drive):
    caminho = f"/content/drive/{pasta_drive}/{nome_arquivo}"
    try:
        df = pd.read_excel(caminho, engine='openpyxl')
        if 'descricao_item_bruta' not in df.columns:
            raise ValueError("Coluna 'descricao_item_bruta' n√£o encontrada.")
        print(f"[OK] Planilha: {len(df)} linhas | descri√ß√µes v√°lidas: {df['descricao_item_bruta'].notna().sum()}", flush=True)
        return df, caminho
    except Exception as e:
        print(f"[ERRO] Falha ao carregar planilha: {e}", flush=True)
        raise

def salvar_relatorio_final(df, pasta_drive):
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    destino = f"/content/drive/{pasta_drive}/relatorio_final_{ts}.xlsx"
    try:
        df.to_excel(destino, index=False, engine='openpyxl')
        print(f"[OK] Relat√≥rio salvo: {os.path.basename(destino)}", flush=True)
        return True, destino
    except Exception as e:
        print(f"[ERRO] Falha ao salvar relat√≥rio: {e}", flush=True)
        return False, None

# =========================
# Chamadas de modelos
# =========================

def consultar_gpt4o(prompt, max_tokens=200, temperatura=0.1):
    for tent in range(1, 4):
        try:
            rsp = openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um auditor brasileiro experiente."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=max_tokens,
                temperature=temperatura
            )
            return rsp.choices[0].message.content.strip()
        except Exception as e:
            print(f"[WARN] GPT tentativa {tent} falhou: {str(e)[:80]}", flush=True)
            time.sleep(3)
    return None

def consultar_claude(prompt, max_tokens=200, temperatura=0.1):
    for tent in range(1, 4):
        try:
            msg = cliente_anthropic.messages.create(
                model="claude-sonnet-4-5-20250929",
                max_tokens=max_tokens,
                temperature=temperatura,
                messages=[{"role": "user", "content": prompt}]
            )
            return msg.content[0].text.strip()
        except Exception as e:
            print(f"[WARN] Claude tentativa {tent} falhou: {str(e)[:80]}", flush=True)
            time.sleep(3)
    return None

def consultar_deepseek(prompt, max_tokens=200, temperatura=0.1):
    for tent in range(1, 4):
        try:
            rsp = cliente_deepseek.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": "You are a helpful assistant"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=max_tokens,
                temperature=temperatura
            )
            return rsp.choices[0].message.content.strip()
        except Exception as e:
            s = str(e)
            if "Insufficient Balance" in s or "402" in s:
                print(f"[WARN] DeepSeek sem saldo (tentativa {tent})", flush=True)
                return None
            print(f"[WARN] DeepSeek tentativa {tent} falhou: {s[:80]}", flush=True)
            time.sleep(3)
    return None

# =========================
# Execu√ß√£o repetida para m√©dia (com tqdm + log)
# =========================

def rodar_precos_em_lote(func_modelo, prompt_preco, n_execucoes=N_EXECUCOES_PRECO, sleep=SLEEP_ENTRE_CHAMADAS, desc_barra="", position=0, item_id="", modelo_nome="", produto=""):
    valores = []
    bar = tqdm(total=n_execucoes, desc=desc_barra, leave=False, position=position, dynamic_ncols=True)
    try:
        for i in range(1, n_execucoes + 1):
            txt = func_modelo(prompt_preco, max_tokens=20, temperatura=0.05)
            raw = repr(txt) if LOG_RAW_RESPOSTA else "<raw oculto>"
            v = extrair_preco(txt)
            if v is not None:
                valores.append(v)
            media_parcial = float(np.mean(valores)) if valores else None
            std_parcial = float(np.std(valores, ddof=1)) if len(valores) > 1 else 0.0 if valores else None
            n_ok = len(valores)

            # Log linha-a-linha de auditoria
            logf(f"{item_id} | {modelo_nome} | produto={produto} | exec={i}/{n_execucoes} | preco={v if v is not None else 'INVALIDO'} | media_parcial={media_parcial if media_parcial is not None else 'NA'} | std_parcial={std_parcial if std_parcial is not None else 'NA'} | n_ok={n_ok} | raw={raw}")

            postfix = {}
            if media_parcial is not None:
                postfix.update(dict(media=f"{media_parcial:.2f}", std=f"{std_parcial:.2f}", n=n_ok))
            bar.set_postfix(postfix)
            bar.update(1)
            time.sleep(sleep)
    finally:
        bar.close()

    if len(valores) == 0:
        return None, None, 0
    media = float(np.mean(valores))
    std = float(np.std(valores, ddof=1)) if len(valores) > 1 else 0.0
    # Log resumo final do modelo
    logf(f"{item_id} | {modelo_nome} | FINAL | media={media:.2f} | std={std:.2f} | n={len(valores)}")
    return media, std, len(valores)

# =========================
# Processo por item (com auditoria)
# =========================

def processar_item_3modelos(descricao_bruta, index, base_position=1):
    r = {
        'produto_identificado_modelo_01': None,
        'preco_estimado_modelo_01': None,
        'preco_std_modelo_01': None,
        'preco_n_modelo_01': 0,

        'produto_identificado_modelo_02': None,
        'preco_estimado_modelo_02': None,
        'preco_std_modelo_02': None,
        'preco_n_modelo_02': 0,

        'produto_identificado_modelo_03': None,
        'preco_estimado_modelo_03': None,
        'preco_std_modelo_03': None,
        'preco_n_modelo_03': 0,

        'prompt_id': f"3MODELS_{index:04d}",
        'status_analise': 'PENDENTE',
        'observacoes': None
    }

    if pd.isna(descricao_bruta) or str(descricao_bruta).strip() == '':
        r['status_analise'] = 'ERRO'
        r['observacoes'] = 'Descri√ß√£o vazia'
        logf(f"ITEM {index+1} | {r['prompt_id']} | descricao=<vazia> | STATUS=ERRO")
        return r

    descricao = str(descricao_bruta).strip()
    logf(f"=== ITEM {index+1} | {r['prompt_id']} ===")
    logf(f"descricao_item_bruta: {descricao}")

    prompt_identificacao = (
        "Voc√™ ver√° a descri√ß√£o de um item de licita√ß√£o.\n\n"
        f'DESCRI√á√ÉO:\n"{descricao}"\n\n'
        "TAREFA:\nIdentifique o produto REAL correspondente no varejo brasileiro. "
        "Inclua marca e modelo quando poss√≠vel.\n\n"
        "Responda APENAS com o nome do produto:"
    )

    prompt_preco_template = (
        "Considere o produto abaixo e informe um pre√ßo m√©dio unit√°rio no varejo do Brasil.\n\n"
        "Produto: {produto}\n\n"
        "Regras:\n"
        "- Pre√ßo de 1 unidade (n√£o atacado)\n"
        "- Pense em lojas brasileiras (Amazon, Magalu, Kabum, Kalunga)\n"
        "- Responda APENAS com o valor num√©rico (ex: 2899.90)\n\n"
        "Pre√ßo:"
    )

    obs = []

    # ---- GPT-4o-mini ----
    try:
        if VERBOSO: print("[GPT-4o-mini] identificando produto...", flush=True)
        prod = consultar_gpt4o(prompt_identificacao, max_tokens=80, temperatura=0.1)
        if prod:
            prod = prod.strip().replace('"', '').replace("'", "")
            r['produto_identificado_modelo_01'] = prod
            logf(f"{r['prompt_id']} | GPT-4o-mini | produto_identificado={prod}")
            if VERBOSO: print(f"[GPT-4o-mini] produto: {prod}", flush=True)
            prompt_preco = prompt_preco_template.format(produto=prod)
            media, desvio, n_ok = rodar_precos_em_lote(
                consultar_gpt4o, prompt_preco,
                n_execucoes=N_EXECUCOES_PRECO,
                sleep=SLEEP_ENTRE_CHAMADAS,
                desc_barra=f"[GPT-4o-mini] pre√ßos",
                position=base_position,
                item_id=r['prompt_id'],
                modelo_nome="GPT-4o-mini",
                produto=prod
            )
            if media is not None:
                r['preco_estimado_modelo_01'] = round(media, 2)
                r['preco_std_modelo_01'] = round(desvio, 2)
                r['preco_n_modelo_01'] = int(n_ok)
        else:
            obs.append("GPT: falha")
            logf(f"{r['prompt_id']} | GPT-4o-mini | FALHA_IDENTIFICACAO")
    except Exception as e:
        obs.append("GPT: erro")
        logf(f"{r['prompt_id']} | GPT-4o-mini | ERRO | {repr(e)}")

    # ---- Claude ----
    try:
        if VERBOSO: print("[Claude] identificando produto...", flush=True)
        prod = consultar_claude(prompt_identificacao, max_tokens=80, temperatura=0.1)
        if prod:
            prod = prod.strip().replace('"', '').replace("'", "")
            r['produto_identificado_modelo_02'] = prod
            logf(f"{r['prompt_id']} | Claude | produto_identificado={prod}")
            if VERBOSO: print(f"[Claude] produto: {prod}", flush=True)
            prompt_preco = prompt_preco_template.format(produto=prod)
            media, desvio, n_ok = rodar_precos_em_lote(
                consultar_claude, prompt_preco,
                n_execucoes=N_EXECUCOES_PRECO,
                sleep=SLEEP_ENTRE_CHAMADAS,
                desc_barra=f"[Claude] pre√ßos",
                position=base_position+1,
                item_id=r['prompt_id'],
                modelo_nome="Claude",
                produto=prod
            )
            if media is not None:
                r['preco_estimado_modelo_02'] = round(media, 2)
                r['preco_std_modelo_02'] = round(desvio, 2)
                r['preco_n_modelo_02'] = int(n_ok)
        else:
            obs.append("Claude: falha")
            logf(f"{r['prompt_id']} | Claude | FALHA_IDENTIFICACAO")
    except Exception as e:
        obs.append("Claude: erro")
        logf(f"{r['prompt_id']} | Claude | ERRO | {repr(e)}")

    # ---- DeepSeek ----
    try:
        if VERBOSO: print("[DeepSeek] identificando produto...", flush=True)
        prod = consultar_deepseek(prompt_identificacao, max_tokens=80, temperatura=0.1)
        if prod:
            prod = prod.strip().replace('"', '').replace("'", "")
            r['produto_identificado_modelo_03'] = prod
            logf(f"{r['prompt_id']} | DeepSeek | produto_identificado={prod}")
            if VERBOSO: print(f"[DeepSeek] produto: {prod}", flush=True)
            prompt_preco = prompt_preco_template.format(produto=prod)
            media, desvio, n_ok = rodar_precos_em_lote(
                consultar_deepseek, prompt_preco,
                n_execucoes=N_EXECUCOES_PRECO,
                sleep=SLEEP_ENTRE_CHAMADAS,
                desc_barra=f"[DeepSeek] pre√ßos",
                position=base_position+2,
                item_id=r['prompt_id'],
                modelo_nome="DeepSeek",
                produto=prod
            )
            if media is not None:
                r['preco_estimado_modelo_03'] = round(media, 2)
                r['preco_std_modelo_03'] = round(desvio, 2)
                r['preco_n_modelo_03'] = int(n_ok)
        else:
            obs.append("DeepSeek: sem saldo ou falha")
            logf(f"{r['prompt_id']} | DeepSeek | FALHA_IDENTIFICACAO")
    except Exception as e:
        obs.append("DeepSeek: erro")
        logf(f"{r['prompt_id']} | DeepSeek | ERRO | {repr(e)}")

    r['status_analise'] = 'PROCESSADO'
    if obs:
        r['observacoes'] = "; ".join(obs)
        logf(f"{r['prompt_id']} | OBSERVACOES: {r['observacoes']}")
    logf(f"=== FIM ITEM {index+1} | {r['prompt_id']} ===")
    return r

# =========================
# Processar planilha (barra geral)
# =========================

def processar_planilha(df, limite_linhas=None):
    n = limite_linhas if limite_linhas else len(df)
    n = min(n, len(df))
    print(f"[INFO] Processando {n} itens (m√©dia de {N_EXECUCOES_PRECO} execu√ß√µes por modelo)", flush=True)

    colunas = {
        'produto_identificado_modelo_01': 'object',
        'preco_estimado_modelo_01': 'float64',
        'preco_std_modelo_01': 'float64',
        'preco_n_modelo_01': 'int64',

        'produto_identificado_modelo_02': 'object',
        'preco_estimado_modelo_02': 'float64',
        'preco_std_modelo_02': 'float64',
        'preco_n_modelo_02': 'int64',

        'produto_identificado_modelo_03': 'object',
        'preco_estimado_modelo_03': 'float64',
        'preco_std_modelo_03': 'float64',
        'preco_n_modelo_03': 'int64',

        'prompt_id': 'object',
        'status_analise': 'object',
        'observacoes': 'object'
    }
    for col, dtype in colunas.items():
        if col not in df.columns:
            df[col] = None
    for col, dtype in colunas.items():
        try:
            df[col] = df[col].astype(dtype)
        except Exception:
            pass

    with tqdm(total=n, desc="[Itens]", position=0, dynamic_ncols=True) as bar_itens:
        processados = 0
        for idx in range(n):
            if pd.notna(df.at[idx, 'status_analise']) and df.at[idx, 'status_analise'] == 'PROCESSADO':
                bar_itens.set_postfix(dict(status="skip"))
                bar_itens.update(1)
                continue

            desc = str(df.iloc[idx].get('descricao_item_bruta', ''))[:80].replace("\n", " ")
            logf(f"----- INICIO PROCESSO ITEM {idx+1}/{n} -----")
            logf(f"descricao_preview: {desc}")
            bar_itens.set_postfix(dict(item=f"{idx+1}/{n}"))
            r = processar_item_3modelos(df.iloc[idx].get('descricao_item_bruta', ''), idx, base_position=1)
            for k, v in r.items():
                df.at[idx, k] = v
            processados += 1
            bar_itens.update(1)
            logf(f"----- FIM PROCESSO ITEM {idx+1}/{n} -----")

    print(f"[OK] Conclu√≠do. Itens processados: {processados}", flush=True)
    return df

# =========================
# Relat√≥rio
# =========================

def gerar_relatorio(df):
    df_proc = df[df['status_analise'] == 'PROCESSADO']
    if len(df_proc) == 0:
        print("[INFO] Nenhum item processado", flush=True)
        return

    print("[RELAT√ìRIO] Resumo de pre√ßos por modelo (m√©dia ¬± desvio, n v√°lidos)", flush=True)
    modelos = [
        (1, "GPT-4o-mini"),
        (2, "Claude Sonnet 4.5"),
        (3, "DeepSeek")
    ]
    for num, nome in modelos:
        col_preco = f'preco_estimado_modelo_0{num}'
        col_std   = f'preco_std_modelo_0{num}'
        col_n     = f'preco_n_modelo_0{num}'
        dfp = df_proc[df_proc[col_preco].notna()]
        if len(dfp) > 0:
            precos = dfp[col_preco].astype(float)
            print(f"- {nome}: linhas com pre√ßo={len(dfp)}/{len(df_proc)} | "
                  f"m√©dia_global={precos.mean():.2f} | mediana={precos.median():.2f} | "
                  f"min={precos.min():.2f} | max={precos.max():.2f}", flush=True)
        else:
            print(f"- {nome}: nenhum pre√ßo", flush=True)

# =========================
# Execu√ß√£o
# =========================

print("[START] LICITA+ v7.6 - auditoria TXT + tqdm", flush=True)
df_licitacoes, _ = carregar_planilha(NOME_ARQUIVO_EXCEL, PASTA_DRIVE)

df_atualizado = processar_planilha(
    df_licitacoes.copy(),
    limite_linhas= None  # ajuste para None para processar tudo
)

ok, _ = salvar_relatorio_final(df_atualizado, PASTA_DRIVE)
gerar_relatorio(df_atualizado)

if LOG_SALVAR_TXT:
    caminho_logs = salvar_logs_txt(PASTA_DRIVE)

print("[END]", flush=True)

# =========================
# Configura√ß√µes
# =========================

NOME_ARQUIVO_EXCEL = "LICITA_plus_dataset_template.xlsx"
PASTA_DRIVE = "My Drive/üìÅ FACULDADE/2025 - 8¬∫ Per√≠odo/Trabalho de Conclus√£o de Curso II"

OPENAI_API_KEY = ""      # use Secrets (google.colab.userdata)
ANTHROPIC_API_KEY = ""   # use Secrets
DEEPSEEK_API_KEY = ""    # use Secrets

# Configura√ß√£o para TESTE - apenas 5 primeiros produtos
LIMITE_TESTE = 5
SLEEP_ENTRE_CHAMADAS = 1.0  # seg

# Logging / Auditoria
VERBOSO = True
LOG_SALVAR_TXT = True
LOG_REGISTROS = []

# =========================
# Instala√ß√£o de deps
# =========================

import subprocess, sys
def instalar():
    deps = [
        "openai>=1.3.0",
        "anthropic>=0.18.0",
        "pandas>=1.5.0",
        "openpyxl>=3.1.0",
        "numpy>=1.23.0",
        "tqdm>=4.66.0"
    ]
    for dep in deps:
        subprocess.check_call([sys.executable, "-m", "pip", "install", dep, "-q"])
instalar()

# =========================
# Imports
# =========================

import pandas as pd
import numpy as np
import openai
import anthropic
import time
import os
import re
from datetime import datetime
from tqdm.auto import tqdm

# =========================
# APIs
# =========================

from google.colab import userdata

OPENAI_API_KEY = userdata.get('OPENAI_API_KEY') or OPENAI_API_KEY
ANTHROPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY') or ANTHROPIC_API_KEY
DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY') or DEEPSEEK_API_KEY

openai.api_key = OPENAI_API_KEY
cliente_anthropic = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)
cliente_deepseek = openai.OpenAI(api_key=DEEPSEEK_API_KEY, base_url="https://api.deepseek.com")

print("[OK] APIs configuradas", flush=True)

# =========================
# Google Drive
# =========================

from google.colab import drive
drive.mount('/content/drive', force_remount=True)
print("[OK] Drive montado", flush=True)

# =========================
# 5 PROMPTS PARA IDENTIFICA√á√ÉO DE PRODUTO
# =========================

PROMPTS_IDENTIFICACAO = {
    "PromptID_1": """Identifique o produto principal desta descri√ß√£o de licita√ß√£o e responda APENAS com o nome do produto (sem quantidades, marcas ou detalhes):

Descri√ß√£o: {descricao}

Produto:""",

    "PromptID_2": """Voc√™ √© um auditor especializado em licita√ß√µes. Analise a descri√ß√£o abaixo e extraia o nome do produto/item principal, respondendo de forma objetiva e concisa:

{descricao}

Nome do produto:""",

    "PromptID_3": """Com base na descri√ß√£o de licita√ß√£o a seguir, qual √© o produto/item sendo licitado? Responda apenas com o nome do produto principal.

Descri√ß√£o da licita√ß√£o:
{descricao}

Resposta:""",

    "PromptID_4": """Analise a descri√ß√£o e identifique o produto:

{descricao}

Qual produto est√° sendo descrito? (responda somente com o nome)""",

    "PromptID_5": """Extraia o produto principal desta descri√ß√£o de compra p√∫blica:

DESCRI√á√ÉO: {descricao}

PRODUTO IDENTIFICADO:"""
}

# =========================
# 5 PROMPTS PARA ESTIMATIVA DE PRE√áO
# =========================

PROMPTS_PRECO = {
    "PromptPreco_1": """Com base no mercado brasileiro, estime o pre√ßo unit√°rio m√©dio em reais (R$) para o produto:

{produto}

Retorne apenas o valor num√©rico (ex: 125.50). Se n√£o souber, retorne "N/A".

Pre√ßo estimado:""",

    "PromptPreco_2": """Voc√™ √© um especialista em precifica√ß√£o de produtos no Brasil. Qual seria o pre√ßo m√©dio de mercado para:

Produto: {produto}

Responda apenas com o valor em reais (exemplo: 89.90):""",

    "PromptPreco_3": """Estime o valor unit√°rio t√≠pico no mercado brasileiro para o seguinte produto:

{produto}

Valor estimado (somente n√∫mero):""",

    "PromptPreco_4": """Considerando o mercado nacional, forne√ßa uma estimativa de pre√ßo para:

{produto}

Pre√ßo em R$ (apenas n√∫mero):""",

    "PromptPreco_5": """Qual o pre√ßo m√©dio de mercado no Brasil para este produto?

PRODUTO: {produto}

PRE√áO (R$):"""
}

# =========================
# Utilit√°rios
# =========================

NUM_REGEX = re.compile(r'(\d{1,6}(?:[.,]\d{1,2})?)')

def extrair_preco(texto):
    if not texto:
        return None
    m = NUM_REGEX.findall(str(texto))
    if not m:
        return None
    try:
        v = float(m[0].replace(',', '.'))
        if 1 <= v <= 50000:
            return round(v, 2)
    except:
        return None
    return None

def logf(msg):
    LOG_REGISTROS.append(msg)

def salvar_logs_txt(pasta_drive):
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    caminho = f"/content/drive/{pasta_drive}/logs_teste_5produtos_{ts}.txt"
    with open(caminho, "w", encoding="utf-8") as f:
        f.write("\n".join(LOG_REGISTROS))
        f.write("\n")
    print(f"[OK] Log salvo: {os.path.basename(caminho)}", flush=True)
    return caminho

# =========================
# Planilha
# =========================

def carregar_planilha(nome_arquivo, pasta_drive):
    caminho = f"/content/drive/{pasta_drive}/{nome_arquivo}"
    try:
        df = pd.read_excel(caminho, engine='openpyxl')
        if 'descricao_item_bruta' not in df.columns:
            raise ValueError("Coluna 'descricao_item_bruta' n√£o encontrada.")
        print(f"[OK] Planilha: {len(df)} linhas | descri√ß√µes v√°lidas: {df['descricao_item_bruta'].notna().sum()}", flush=True)
        return df, caminho
    except Exception as e:
        print(f"[ERRO] Falha ao carregar planilha: {e}", flush=True)
        raise

def salvar_relatorio_final(df, pasta_drive):
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    destino = f"/content/drive/{pasta_drive}/Resultado_Varios_Prompts_{ts}.xlsx"
    try:
        # Criar um Excel writer para formatar melhor
        with pd.ExcelWriter(destino, engine='openpyxl') as writer:
            # Aba 1: Dados completos
            df.to_excel(writer, sheet_name='Dados_Completos', index=False)

            # Ajustar largura das colunas
            worksheet = writer.sheets['Dados_Completos']
            for column in worksheet.columns:
                max_length = 0
                column_letter = column[0].column_letter
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                adjusted_width = min(max_length + 2, 50)
                worksheet.column_dimensions[column_letter].width = adjusted_width

        print(f"[OK] Relat√≥rio salvo: {os.path.basename(destino)}", flush=True)
        return True, destino
    except Exception as e:
        print(f"[ERRO] Falha ao salvar relat√≥rio: {e}", flush=True)
        return False, None

# =========================
# Chamadas de modelos
# =========================

def consultar_gpt4o(prompt, max_tokens=200, temperatura=0.1):
    for tent in range(1, 4):
        try:
            rsp = openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um auditor brasileiro experiente."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=max_tokens,
                temperature=temperatura
            )
            return rsp.choices[0].message.content.strip()
        except Exception as e:
            print(f"[WARN] GPT tentativa {tent} falhou: {str(e)[:80]}", flush=True)
            time.sleep(3)
    return None

def consultar_claude(prompt, max_tokens=200, temperatura=0.1):
    for tent in range(1, 4):
        try:
            msg = cliente_anthropic.messages.create(
                model="claude-sonnet-4-5-20250929",
                max_tokens=max_tokens,
                temperature=temperatura,
                messages=[{"role": "user", "content": prompt}]
            )
            return msg.content[0].text.strip()
        except Exception as e:
            print(f"[WARN] Claude tentativa {tent} falhou: {str(e)[:80]}", flush=True)
            time.sleep(3)
    return None

def consultar_deepseek(prompt, max_tokens=200, temperatura=0.1):
    for tent in range(1, 4):
        try:
            rsp = cliente_deepseek.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": "You are a helpful assistant"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=max_tokens,
                temperature=temperatura
            )
            return rsp.choices[0].message.content.strip()
        except Exception as e:
            s = str(e)
            if "Insufficient Balance" in s or "402" in s:
                print(f"[WARN] DeepSeek sem saldo (tentativa {tent})", flush=True)
                return None
            print(f"[WARN] DeepSeek tentativa {tent} falhou: {s[:80]}", flush=True)
            time.sleep(3)
    return None

# =========================
# Processar item com TODOS os prompts
# =========================

def processar_item_completo(descricao, index):
    """
    Processa UM item com:
    - 5 prompts de identifica√ß√£o √ó 3 modelos = 15 identifica√ß√µes
    - Para cada produto identificado, 5 prompts de pre√ßo √ó 3 modelos = at√© 75 pre√ßos
    Total m√°ximo: 90 chamadas por item
    """
    r = {
        'item_index': index + 1,
        'descricao_original': descricao[:200] + "..." if len(descricao) > 200 else descricao,
        'status_analise': 'PENDENTE',
        'observacoes': ''
    }

    obs = []
    logf(f"\n{'='*80}")
    logf(f"ITEM {index+1} - INICIO DO PROCESSAMENTO")
    logf(f"{'='*80}")

    modelos_config = [
        ('GPT4o', consultar_gpt4o),
        ('Claude', consultar_claude),
        ('DeepSeek', consultar_deepseek)
    ]

    # Para cada PROMPT DE IDENTIFICA√á√ÉO
    for prompt_id_id, prompt_id_template in PROMPTS_IDENTIFICACAO.items():
        logf(f"\n--- Testando {prompt_id_id} ---")

        prompt_identificacao = prompt_id_template.format(descricao=descricao[:500])

        # Para cada MODELO
        for modelo_nome, funcao_modelo in modelos_config:
            col_produto = f'Produto_Identificado_{prompt_id_id}_{modelo_nome}'

            try:
                if VERBOSO:
                    print(f"[{prompt_id_id}] [{modelo_nome}] identificando...", flush=True)

                prod = funcao_modelo(prompt_identificacao, max_tokens=80, temperatura=0.1)

                if prod:
                    prod = prod.strip().replace('"', '').replace("'", "")
                    r[col_produto] = prod
                    logf(f"{prompt_id_id} | {modelo_nome} | Produto identificado: {prod}")

                    # Agora, para cada PROMPT DE PRE√áO
                    for prompt_preco_id, prompt_preco_template in PROMPTS_PRECO.items():
                        col_preco = f'Preco_{prompt_id_id}_{prompt_preco_id}_{modelo_nome}'

                        try:
                            prompt_preco = prompt_preco_template.format(produto=prod)
                            preco_resp = funcao_modelo(prompt_preco, max_tokens=100, temperatura=0.1)
                            preco = extrair_preco(preco_resp)

                            if preco:
                                r[col_preco] = round(preco, 2)
                                logf(f"  ‚îî‚îÄ {prompt_preco_id} | {modelo_nome} | Pre√ßo: R$ {preco:.2f}")
                            else:
                                r[col_preco] = None
                                logf(f"  ‚îî‚îÄ {prompt_preco_id} | {modelo_nome} | Pre√ßo: FALHA")

                            time.sleep(SLEEP_ENTRE_CHAMADAS)

                        except Exception as e:
                            r[col_preco] = None
                            logf(f"  ‚îî‚îÄ {prompt_preco_id} | {modelo_nome} | ERRO: {repr(e)}")

                else:
                    r[col_produto] = None
                    obs.append(f"{prompt_id_id}-{modelo_nome}: falha identifica√ß√£o")
                    logf(f"{prompt_id_id} | {modelo_nome} | FALHA na identifica√ß√£o")

                time.sleep(SLEEP_ENTRE_CHAMADAS)

            except Exception as e:
                r[col_produto] = None
                obs.append(f"{prompt_id_id}-{modelo_nome}: erro")
                logf(f"{prompt_id_id} | {modelo_nome} | ERRO: {repr(e)}")

    r['status_analise'] = 'PROCESSADO'
    if obs:
        r['observacoes'] = "; ".join(obs[:10])  # Limitar observa√ß√µes

    logf(f"\n{'='*80}")
    logf(f"ITEM {index+1} - FIM DO PROCESSAMENTO")
    logf(f"{'='*80}\n")

    return r

# =========================
# Processar planilha (5 primeiros)
# =========================

def processar_planilha_teste(df):
    n = min(LIMITE_TESTE, len(df))
    print(f"\n{'='*80}")
    print(f"[TESTE] Processando {n} primeiros produtos")
    print(f"[CONFIG] 5 prompts identifica√ß√£o √ó 3 modelos = 15 identifica√ß√µes/produto")
    print(f"[CONFIG] 5 prompts pre√ßo √ó 3 modelos = 15 pre√ßos/produto identificado")
    print(f"{'='*80}\n")

    resultados = []

    with tqdm(total=n, desc="[Produtos]", position=0, dynamic_ncols=True) as bar:
        for idx in range(n):
            desc = df.iloc[idx].get('descricao_item_bruta', '')

            if pd.isna(desc) or str(desc).strip() == '':
                print(f"[SKIP] Item {idx+1}: sem descri√ß√£o", flush=True)
                bar.update(1)
                continue

            bar.set_postfix(dict(item=f"{idx+1}/{n}"))

            resultado = processar_item_completo(desc, idx)
            resultados.append(resultado)

            bar.update(1)

    print(f"\n[OK] Processamento conclu√≠do!", flush=True)

    # Criar DataFrame com os resultados
    df_resultados = pd.DataFrame(resultados)

    return df_resultados

# =========================
# An√°lise e Relat√≥rios
# =========================

def criar_analise_completa(df_resultados, pasta_drive):
    """
    Cria an√°lises detalhadas e salva em abas separadas do Excel
    """
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    destino = f"/content/drive/{pasta_drive}/Resultado_Varios_Prompts_{ts}.xlsx"

    try:
        with pd.ExcelWriter(destino, engine='openpyxl') as writer:
            # ABA 1: Dados Completos
            df_resultados.to_excel(writer, sheet_name='Dados_Completos', index=False)

            # ABA 2: An√°lise de Identifica√ß√£o
            analise_id = analisar_identificacao(df_resultados)
            analise_id.to_excel(writer, sheet_name='Analise_Identificacao', index=False)

            # ABA 3: An√°lise de Pre√ßos
            analise_preco = analisar_precos(df_resultados)
            analise_preco.to_excel(writer, sheet_name='Analise_Precos', index=False)

            # ABA 4: Ranking Geral
            ranking = criar_ranking_geral(df_resultados)
            ranking.to_excel(writer, sheet_name='Ranking_Prompts', index=False)

            # ABA 5: Estat√≠sticas por Modelo
            stats_modelo = estatisticas_por_modelo(df_resultados)
            stats_modelo.to_excel(writer, sheet_name='Stats_por_Modelo', index=False)

            # Ajustar largura das colunas em todas as abas
            for sheet_name in writer.sheets:
                worksheet = writer.sheets[sheet_name]
                for column in worksheet.columns:
                    max_length = 0
                    column_letter = column[0].column_letter
                    for cell in column:
                        try:
                            if len(str(cell.value)) > max_length:
                                max_length = len(str(cell.value))
                        except:
                            pass
                    adjusted_width = min(max_length + 2, 60)
                    worksheet.column_dimensions[column_letter].width = adjusted_width

        print(f"\n[OK] Relat√≥rio completo salvo: {os.path.basename(destino)}", flush=True)
        return destino

    except Exception as e:
        print(f"[ERRO] Falha ao criar an√°lise: {e}", flush=True)
        return None

def analisar_identificacao(df):
    """Analisa taxa de sucesso na identifica√ß√£o de produtos"""
    resultados = []

    for prompt_id in PROMPTS_IDENTIFICACAO.keys():
        for modelo in ['GPT4o', 'Claude', 'DeepSeek']:
            col = f'Produto_Identificado_{prompt_id}_{modelo}'
            if col in df.columns:
                total = len(df)
                sucesso = df[col].notna().sum()
                taxa = (sucesso / total * 100) if total > 0 else 0

                resultados.append({
                    'Prompt_Identificacao': prompt_id,
                    'Modelo': modelo,
                    'Total_Itens': total,
                    'Identificacoes_Sucesso': sucesso,
                    'Taxa_Sucesso_%': round(taxa, 1)
                })

    return pd.DataFrame(resultados)

def analisar_precos(df):
    """Analisa pre√ßos obtidos por cada combina√ß√£o"""
    resultados = []

    for prompt_id in PROMPTS_IDENTIFICACAO.keys():
        for prompt_preco in PROMPTS_PRECO.keys():
            for modelo in ['GPT4o', 'Claude', 'DeepSeek']:
                col = f'Preco_{prompt_id}_{prompt_preco}_{modelo}'
                if col in df.columns:
                    precos = df[col].dropna()
                    if len(precos) > 0:
                        resultados.append({
                            'Prompt_Identificacao': prompt_id,
                            'Prompt_Preco': prompt_preco,
                            'Modelo': modelo,
                            'N_Precos': len(precos),
                            'Preco_Medio': round(precos.mean(), 2),
                            'Preco_Mediano': round(precos.median(), 2),
                            'Preco_Min': round(precos.min(), 2),
                            'Preco_Max': round(precos.max(), 2),
                            'Desvio_Padrao': round(precos.std(), 2)
                        })

    return pd.DataFrame(resultados)

def criar_ranking_geral(df):
    """Cria ranking das melhores combina√ß√µes"""
    resultados = []

    # Para cada combina√ß√£o de prompts
    for prompt_id in PROMPTS_IDENTIFICACAO.keys():
        for prompt_preco in PROMPTS_PRECO.keys():
            score_total = 0
            n_precos_total = 0

            for modelo in ['GPT4o', 'Claude', 'DeepSeek']:
                col = f'Preco_{prompt_id}_{prompt_preco}_{modelo}'
                if col in df.columns:
                    n_precos = df[col].notna().sum()
                    n_precos_total += n_precos
                    score_total += n_precos

            taxa = (n_precos_total / (len(df) * 3) * 100) if len(df) > 0 else 0

            resultados.append({
                'Prompt_Identificacao': prompt_id,
                'Prompt_Preco': prompt_preco,
                'Total_Precos_Obtidos': n_precos_total,
                'Taxa_Sucesso_%': round(taxa, 1),
                'Score': score_total
            })

    df_ranking = pd.DataFrame(resultados)
    df_ranking = df_ranking.sort_values('Score', ascending=False)
    df_ranking['Ranking'] = range(1, len(df_ranking) + 1)

    return df_ranking[['Ranking', 'Prompt_Identificacao', 'Prompt_Preco',
                       'Total_Precos_Obtidos', 'Taxa_Sucesso_%', 'Score']]

def estatisticas_por_modelo(df):
    """Estat√≠sticas gerais por modelo"""
    resultados = []

    for modelo in ['GPT4o', 'Claude', 'DeepSeek']:
        # Contar identifica√ß√µes
        cols_id = [col for col in df.columns if col.startswith('Produto_Identificado_') and col.endswith(f'_{modelo}')]
        total_id = sum(df[col].notna().sum() for col in cols_id)

        # Contar pre√ßos
        cols_preco = [col for col in df.columns if col.startswith('Preco_') and col.endswith(f'_{modelo}')]
        total_precos = sum(df[col].notna().sum() for col in cols_preco)

        # Calcular m√©dias de pre√ßo
        todos_precos = []
        for col in cols_preco:
            todos_precos.extend(df[col].dropna().tolist())

        resultados.append({
            'Modelo': modelo,
            'Total_Identificacoes': total_id,
            'Total_Precos': total_precos,
            'Preco_Medio_Geral': round(np.mean(todos_precos), 2) if todos_precos else 0,
            'Preco_Mediano_Geral': round(np.median(todos_precos), 2) if todos_precos else 0
        })

    return pd.DataFrame(resultados)

def imprimir_resumo_console(df):
    """Imprime resumo no console"""
    print("\n" + "="*80)
    print("RESUMO DA AN√ÅLISE")
    print("="*80)

    print(f"\nüìä Total de produtos analisados: {len(df)}")

    # Total de colunas criadas
    cols_produto = [col for col in df.columns if col.startswith('Produto_Identificado_')]
    cols_preco = [col for col in df.columns if col.startswith('Preco_')]

    print(f"üìù Total de colunas de identifica√ß√£o: {len(cols_produto)}")
    print(f"üí∞ Total de colunas de pre√ßo: {len(cols_preco)}")

    # Taxa geral de sucesso
    total_id_esperadas = len(df) * len(PROMPTS_IDENTIFICACAO) * 3
    total_id_obtidas = sum(df[col].notna().sum() for col in cols_produto)
    taxa_id = (total_id_obtidas / total_id_esperadas * 100) if total_id_esperadas > 0 else 0

    print(f"\n‚úÖ Taxa geral de identifica√ß√£o: {taxa_id:.1f}% ({total_id_obtidas}/{total_id_esperadas})")

    # Melhor modelo
    for modelo in ['GPT4o', 'Claude', 'DeepSeek']:
        cols_modelo = [col for col in cols_produto if col.endswith(f'_{modelo}')]
        sucesso = sum(df[col].notna().sum() for col in cols_modelo)
        print(f"   - {modelo}: {sucesso} identifica√ß√µes")

    print("\n" + "="*80 + "\n")

# =========================
# Execu√ß√£o Principal
# =========================

print("\n" + "="*80)
print("LICITA+ - TESTE COM M√öLTIPLOS PROMPTS")
print("="*80)
print(f"Vers√£o: Teste com {LIMITE_TESTE} produtos")
print(f"Prompts de Identifica√ß√£o: {len(PROMPTS_IDENTIFICACAO)}")
print(f"Prompts de Pre√ßo: {len(PROMPTS_PRECO)}")
print(f"Modelos: 3 (GPT-4o-mini, Claude, DeepSeek)")
print("="*80 + "\n")

# Carregar planilha
df_licitacoes, _ = carregar_planilha(NOME_ARQUIVO_EXCEL, PASTA_DRIVE)

# Processar os 5 primeiros
df_resultados = processar_planilha_teste(df_licitacoes)

# Criar an√°lise completa
caminho_relatorio = criar_analise_completa(df_resultados, PASTA_DRIVE)

# Imprimir resumo
imprimir_resumo_console(df_resultados)

# Salvar logs
if LOG_SALVAR_TXT:
    caminho_logs = salvar_logs_txt(PASTA_DRIVE)

print(f"\n‚úÖ FINALIZADO COM SUCESSO!")
print(f"üìÅ Relat√≥rio: {os.path.basename(caminho_relatorio) if caminho_relatorio else 'erro ao salvar'}")
print("\n")

NOME_ARQUIVO_EXCEL = "relatorio_final_20251016_023256.xlsx"
PASTA_DRIVE = "My Drive/üìÅ FACULDADE/2025 - 8¬∫ Per√≠odo/Trabalho de Conclus√£o de Curso II"

OPENAI_API_KEY = ""      # use Secrets (google.colab.userdata)
ANTHROPIC_API_KEY = ""   # use Secrets
DEEPSEEK_API_KEY = ""    # use Secrets

# Configura√ß√µes
SLEEP_ENTRE_CHAMADAS = 1.0  # segundos
VERBOSO = True
LOG_SALVAR_TXT = True
LOG_REGISTROS = []

# =========================
# Instala√ß√£o de depend√™ncias
# =========================

import subprocess, sys
def instalar():
    deps = [
        "openai>=1.3.0",
        "anthropic>=0.18.0",
        "pandas>=1.5.0",
        "openpyxl>=3.1.0",
        "numpy>=1.23.0",
        "tqdm>=4.66.0"
    ]
    for dep in deps:
        subprocess.check_call([sys.executable, "-m", "pip", "install", dep, "-q"])
instalar()

# =========================
# Imports
# =========================

import pandas as pd
import numpy as np
import openai
import anthropic
import time
import os
from datetime import datetime
from tqdm.auto import tqdm

# =========================
# Configura√ß√£o de APIs
# =========================

from google.colab import userdata

OPENAI_API_KEY = userdata.get('OPENAI_API_KEY') or OPENAI_API_KEY
ANTHROPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY') or ANTHROPIC_API_KEY
DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY') or DEEPSEEK_API_KEY

openai.api_key = OPENAI_API_KEY
cliente_anthropic = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)
cliente_deepseek = openai.OpenAI(api_key=DEEPSEEK_API_KEY, base_url="https://api.deepseek.com")

print("[OK] APIs configuradas", flush=True)

# =========================
# Google Drive
# =========================

from google.colab import drive
drive.mount('/content/drive', force_remount=True)
print("[OK] Drive montado", flush=True)

# =========================
# Utilit√°rios
# =========================

def logf(msg):
    LOG_REGISTROS.append(msg)
    if VERBOSO:
        print(msg, flush=True)

def salvar_logs_txt(pasta_drive):
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    caminho = f"/content/drive/{pasta_drive}/logs_comparacao_{ts}.txt"
    with open(caminho, "w", encoding="utf-8") as f:
        f.write("\n".join(LOG_REGISTROS))
        f.write("\n")
    print(f"[OK] Log salvo: {os.path.basename(caminho)}", flush=True)
    return caminho

# =========================
# Carregar Planilha
# =========================

def carregar_planilha(nome_arquivo, pasta_drive):
    caminho = f"/content/drive/{pasta_drive}/{nome_arquivo}"
    try:
        df = pd.read_excel(caminho, engine='openpyxl')
        print(f"[OK] Planilha carregada: {len(df)} linhas", flush=True)
        print(f"[INFO] Colunas dispon√≠veis: {list(df.columns)}", flush=True)
        return df, caminho
    except Exception as e:
        print(f"[ERRO] Falha ao carregar planilha: {e}", flush=True)
        raise

def salvar_relatorio_comparacao(df, pasta_drive):
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    destino = f"/content/drive/{pasta_drive}/comparacao_equivalencia_{ts}.xlsx"
    try:
        df.to_excel(destino, index=False, engine='openpyxl')
        print(f"[OK] Relat√≥rio salvo: {os.path.basename(destino)}", flush=True)
        return True, destino
    except Exception as e:
        print(f"[ERRO] Falha ao salvar relat√≥rio: {e}", flush=True)
        return False, None

# =========================
# Fun√ß√µes de Consulta LLM
# =========================

def consultar_gpt4o(prompt, max_tokens=50, temperatura=0.0):
    for tent in range(1, 4):
        try:
            rsp = openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um especialista em compara√ß√£o de produtos. Responda apenas SIM ou N√ÉO."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=max_tokens,
                temperature=temperatura
            )
            return rsp.choices[0].message.content.strip()
        except Exception as e:
            logf(f"[WARN] GPT tentativa {tent} falhou: {str(e)[:100]}")
            time.sleep(3)
    return None

def consultar_claude(prompt, max_tokens=50, temperatura=0.0):
    for tent in range(1, 4):
        try:
            msg = cliente_anthropic.messages.create(
                model="claude-sonnet-4-5-20250929",
                max_tokens=max_tokens,
                temperature=temperatura,
                messages=[{"role": "user", "content": prompt}]
            )
            return msg.content[0].text.strip()
        except Exception as e:
            logf(f"[WARN] Claude tentativa {tent} falhou: {str(e)[:100]}")
            time.sleep(3)
    return None

def consultar_deepseek(prompt, max_tokens=50, temperatura=0.0):
    for tent in range(1, 4):
        try:
            rsp = cliente_deepseek.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": "You are a product comparison expert. Answer only YES or NO."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=max_tokens,
                temperature=temperatura
            )
            return rsp.choices[0].message.content.strip()
        except Exception as e:
            s = str(e)
            if "Insufficient Balance" in s or "402" in s:
                logf(f"[WARN] DeepSeek sem saldo (tentativa {tent})")
                return None
            logf(f"[WARN] DeepSeek tentativa {tent} falhou: {s[:100]}")
            time.sleep(3)
    return None

# =========================
# Prompt de Compara√ß√£o
# =========================

def criar_prompt_comparacao(produto_llm, produto_manual):
    """Cria o prompt para comparar dois produtos"""
    prompt = f"""Compare os seguintes produtos e determine se s√£o EQUIVALENTES:

Produto 1 (identificado por LLM): {produto_llm}
Produto 2 (identificado manualmente): {produto_manual}

Os produtos s√£o considerados EQUIVALENTES se:
- Possuem as mesmas caracter√≠sticas essenciais
- T√™m a mesma funcionalidade/aplica√ß√£o
- S√£o da mesma categoria/tipo
- Possuem qualidade similar

IMPORTANTE: N√£o precisam ser EXATAMENTE o mesmo produto ou mesma marca, apenas equivalentes em fun√ß√£o e qualidade.

Responda APENAS com uma das op√ß√µes:
- SIM (se s√£o equivalentes)
- N√ÉO (se n√£o s√£o equivalentes)
- INCONCLUSIVO (se n√£o h√° informa√ß√£o suficiente para decidir)

Resposta:"""
    return prompt

# =========================
# Normalizar Resposta
# =========================

def normalizar_resposta(texto):
    """Normaliza a resposta do LLM para SIM, N√ÉO ou INCONCLUSIVO"""
    if not texto:
        return "INCONCLUSIVO"

    texto = texto.upper().strip()

    # Verifica respostas diretas
    if "SIM" in texto or "YES" in texto or "EQUIVALENTE" in texto:
        return "SIM"
    elif "N√ÉO" in texto or "NAO" in texto or "NO" in texto or "NOT" in texto:
        return "N√ÉO"
    else:
        return "INCONCLUSIVO"

# =========================
# Comparar Produtos
# =========================

def comparar_produtos_completo(row, index):
    """
    Compara cada produto LLM com cada produto manual usando os 3 LLMs
    Total: 9 compara√ß√µes (3 produtos LLM √ó 3 produtos manuais)
    """
    resultados = {}

    # Produtos identificados pelos LLMs
    produtos_llm = {
        'GPT': row.get('produto_identificado_modelo_01', None),
        'Claude': row.get('produto_identificado_modelo_02', None),
        'DeepSeek': row.get('produto_identificado_modelo_03', None)
    }

    # Produtos manuais (os nomes dos produtos, n√£o os pre√ßos!)
    produtos_manuais = {
        'Manual1': row.get('fonte_preco_ref1', None),
        'Manual2': row.get('fonte_preco_ref2', None),
        'Manual3': row.get('fonte_preco_ref3', None)
    }

    logf(f"\n{'='*80}")
    logf(f"ITEM {index + 1}")
    logf(f"{'='*80}")

    # Mapear fun√ß√µes LLM
    llms_funcoes = {
        'GPT': consultar_gpt4o,
        'Claude': consultar_claude,
        'DeepSeek': consultar_deepseek
    }

    comparacoes_realizadas = 0
    total_comparacoes = 0

    # Para cada produto identificado pelo LLM
    for nome_llm, produto_llm in produtos_llm.items():
        if not produto_llm or pd.isna(produto_llm):
            logf(f"[SKIP] {nome_llm}: produto n√£o identificado")
            continue

        # Para cada produto manual
        for nome_manual, produto_manual in produtos_manuais.items():
            if not produto_manual or pd.isna(produto_manual):
                continue

            logf(f"\n--- Comparando {nome_llm} √ó {nome_manual} ---")
            logf(f"Produto LLM ({nome_llm}): {produto_llm}")
            logf(f"Produto Manual ({nome_manual}): {produto_manual}")

            # Usar cada um dos 3 LLMs para fazer a compara√ß√£o
            for nome_llm_avaliador, func_llm in llms_funcoes.items():
                total_comparacoes += 1
                col_name = f"comp_{nome_llm}_vs_{nome_manual}_{nome_llm_avaliador}"

                try:
                    prompt = criar_prompt_comparacao(produto_llm, produto_manual)
                    resposta = func_llm(prompt, max_tokens=50, temperatura=0.0)
                    resposta_normalizada = normalizar_resposta(resposta)

                    resultados[col_name] = resposta_normalizada
                    comparacoes_realizadas += 1

                    logf(f"  [{nome_llm_avaliador}] Resposta: {resposta_normalizada} (raw: {resposta})")

                    time.sleep(SLEEP_ENTRE_CHAMADAS)

                except Exception as e:
                    resultados[col_name] = "ERRO"
                    logf(f"  [{nome_llm_avaliador}] ERRO: {str(e)[:100]}")

    # Calcular estat√≠sticas
    resultados['total_comparacoes_realizadas'] = comparacoes_realizadas
    resultados['total_comparacoes_possiveis'] = total_comparacoes

    # Contar respostas
    valores = [v for v in resultados.values() if isinstance(v, str) and v in ['SIM', 'N√ÉO', 'INCONCLUSIVO']]
    resultados['total_sim'] = valores.count('SIM')
    resultados['total_nao'] = valores.count('N√ÉO')
    resultados['total_inconclusivo'] = valores.count('INCONCLUSIVO')

    if valores:
        resultados['percentual_equivalencia'] = round((resultados['total_sim'] / len(valores)) * 100, 2)
    else:
        resultados['percentual_equivalencia'] = None

    logf(f"\n[RESUMO ITEM {index + 1}]")
    logf(f"Compara√ß√µes realizadas: {comparacoes_realizadas}/{total_comparacoes}")
    logf(f"SIM: {resultados['total_sim']} | N√ÉO: {resultados['total_nao']} | INCONCLUSIVO: {resultados['total_inconclusivo']}")
    logf(f"Percentual de equival√™ncia: {resultados['percentual_equivalencia']}%")

    return resultados

# =========================
# Processar Planilha
# =========================

def processar_planilha_comparacao(df, limite_linhas=None):
    """Processa a planilha fazendo as compara√ß√µes"""
    n = limite_linhas if limite_linhas else len(df)
    n = min(n, len(df))

    print(f"\n[INFO] Iniciando compara√ß√£o de equival√™ncia", flush=True)
    print(f"[INFO] Total de itens: {n}", flush=True)
    print(f"[INFO] Compara√ß√µes por item: at√© 9 (3 LLMs identificadores √ó 3 produtos manuais √ó 1 LLM avaliador)", flush=True)
    print(f"[INFO] Na verdade s√£o 27 compara√ß√µes (3 LLMs √ó 3 produtos manuais √ó 3 LLMs avaliadores)", flush=True)

    # Criar colunas para resultados
    # Formato: comp_{LLM_identificador}_vs_{Manual}__{LLM_avaliador}
    nomes_llm = ['GPT', 'Claude', 'DeepSeek']
    nomes_manual = ['Manual1', 'Manual2', 'Manual3']

    for llm in nomes_llm:
        for manual in nomes_manual:
            for avaliador in nomes_llm:
                col_name = f"comp_{llm}_vs_{manual}_{avaliador}"
                if col_name not in df.columns:
                    df[col_name] = None

    # Colunas de estat√≠sticas
    colunas_stats = [
        'total_comparacoes_realizadas',
        'total_comparacoes_possiveis',
        'total_sim',
        'total_nao',
        'total_inconclusivo',
        'percentual_equivalencia'
    ]
    for col in colunas_stats:
        if col not in df.columns:
            df[col] = None

    # Processar cada linha
    with tqdm(total=n, desc="[Comparando]", position=0, dynamic_ncols=True) as pbar:
        for idx in range(n):
            pbar.set_postfix(dict(item=f"{idx+1}/{n}"))

            resultados = comparar_produtos_completo(df.iloc[idx], idx)

            # Atualizar DataFrame
            for col, valor in resultados.items():
                df.at[idx, col] = valor

            pbar.update(1)

    print(f"\n[OK] Compara√ß√£o conclu√≠da!", flush=True)
    return df

# =========================
# Gerar Relat√≥rio Estat√≠stico
# =========================

def gerar_relatorio_estatistico(df):
    """Gera relat√≥rio com estat√≠sticas das compara√ß√µes"""
    print("\n" + "="*80)
    print("RELAT√ìRIO DE COMPARA√á√ÉO DE EQUIVAL√äNCIA")
    print("="*80)

    # Filtrar apenas linhas processadas
    df_proc = df[df['total_comparacoes_realizadas'].notna()]

    if len(df_proc) == 0:
        print("[INFO] Nenhuma compara√ß√£o realizada")
        return

    print(f"\nItens processados: {len(df_proc)}")
    print(f"Total de compara√ß√µes realizadas: {df_proc['total_comparacoes_realizadas'].sum():.0f}")

    print("\n--- Distribui√ß√£o de Respostas ---")
    print(f"SIM (equivalentes): {df_proc['total_sim'].sum():.0f}")
    print(f"N√ÉO (n√£o equivalentes): {df_proc['total_nao'].sum():.0f}")
    print(f"INCONCLUSIVO: {df_proc['total_inconclusivo'].sum():.0f}")

    print("\n--- Percentual de Equival√™ncia ---")
    perc_equiv = df_proc['percentual_equivalencia'].dropna()
    if len(perc_equiv) > 0:
        print(f"M√©dia: {perc_equiv.mean():.2f}%")
        print(f"Mediana: {perc_equiv.median():.2f}%")
        print(f"Desvio padr√£o: {perc_equiv.std():.2f}%")
        print(f"M√≠nimo: {perc_equiv.min():.2f}%")
        print(f"M√°ximo: {perc_equiv.max():.2f}%")

    # An√°lise por LLM identificador
    print("\n--- Equival√™ncia por LLM Identificador ---")
    nomes_llm = ['GPT', 'Claude', 'DeepSeek']
    for llm in nomes_llm:
        # Pegar todas as colunas de compara√ß√£o deste LLM
        cols_llm = [col for col in df.columns if col.startswith(f"comp_{llm}_vs_")]
        if cols_llm:
            # Contar SIM para este LLM
            total_sim = 0
            total_respostas = 0
            for col in cols_llm:
                valores = df_proc[col].dropna()
                total_sim += (valores == 'SIM').sum()
                total_respostas += len(valores[valores.isin(['SIM', 'N√ÉO', 'INCONCLUSIVO'])])

            if total_respostas > 0:
                perc = (total_sim / total_respostas) * 100
                print(f"{llm}: {perc:.2f}% equival√™ncia ({total_sim}/{total_respostas})")

    print("\n" + "="*80)

# =========================
# Execu√ß√£o Principal
# =========================

print("\n[START] Compara√ß√£o de Equival√™ncia de Produtos", flush=True)
print("[INFO] Este script compara produtos identificados por LLMs com produtos manuais", flush=True)

# Carregar planilha
df_original, _ = carregar_planilha(NOME_ARQUIVO_EXCEL, PASTA_DRIVE)

# Processar compara√ß√µes
df_resultado = processar_planilha_comparacao(
    df_original.copy(),
    limite_linhas=None  # None para processar tudo
)

# Salvar resultado
ok, caminho_resultado = salvar_relatorio_comparacao(df_resultado, PASTA_DRIVE)

# Gerar relat√≥rio estat√≠stico
if ok:
    gerar_relatorio_estatistico(df_resultado)

# Salvar logs
if LOG_SALVAR_TXT:
    caminho_logs = salvar_logs_txt(PASTA_DRIVE)

print("\n[END] Processamento conclu√≠do!", flush=True)